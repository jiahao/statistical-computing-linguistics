\documentclass[11pt]{asaproc}

\usepackage{microtype}
\usepackage{hyperref}
\usepackage{listings}

% Use an APL-friendly font
\usepackage{fontspec}
\usepackage{mathptmx}
%Download this font from
%http://misc.aplteam.com/apl385.ttf
\setmonofont{APL385}

\lstdefinelanguage{apl}{
  morecomment=[l]{‚çù},
  commentstyle={},
  morestring=[b]',
}

\lstdefinelanguage{julia}{
  keywordstyle={\textbf},
  morekeywords={if,else,elseif,while,for,begin,end,quote,try,catch,return,local,abstract,function,generated,macro,ccall,finally,typealias,break,continue,type,global,module,using,import,export,const,let,bitstype,do,in,baremodule,importall,immutable},
  escapeinside={~}{~},
  morecomment=[l]{\#},
  commentstyle={},
  morestring=[b]",
}

\lstset{language=julia, numbers=left, numberstyle=\tiny, mathescape=true,
  basicstyle=\small\ttfamily,
  showspaces=false,
  showstringspaces=false,
}

% https://analyzethedatanotthedrivel.org/2011/08/15/typesetting-utf8-apl-code-with-the-latex-lstlisting-package/
% set lstlisting to accept UTF8 APL text
\makeatletter
\lst@InputCatcodes
\def\lst@DefEC{%
 \lst@CCECUse \lst@ProcessLetter
  ^^80^^81^^82^^83^^84^^85^^86^^87^^88^^89^^8a^^8b^^8c^^8d^^8e^^8f%
  ^^90^^91^^92^^93^^94^^95^^96^^97^^98^^99^^9a^^9b^^9c^^9d^^9e^^9f%
  ^^a0^^a1^^a2^^a3^^a4^^a5^^a6^^a7^^a8^^a9^^aa^^ab^^ac^^ad^^ae^^af%
  ^^b0^^b1^^b2^^b3^^b4^^b5^^b6^^b7^^b8^^b9^^ba^^bb^^bc^^bd^^be^^bf%
  ^^c0^^c1^^c2^^c3^^c4^^c5^^c6^^c7^^c8^^c9^^ca^^cb^^cc^^cd^^ce^^cf%
  ^^d0^^d1^^d2^^d3^^d4^^d5^^d6^^d7^^d8^^d9^^da^^db^^dc^^dd^^de^^df%
  ^^e0^^e1^^e2^^e3^^e4^^e5^^e6^^e7^^e8^^e9^^ea^^eb^^ec^^ed^^ee^^ef%
  ^^f0^^f1^^f2^^f3^^f4^^f5^^f6^^f7^^f8^^f9^^fa^^fb^^fc^^fd^^fe^^ff%
  ^^^^20ac^^^^0153^^^^0152%
  ^^^^20a7^^^^2190^^^^2191^^^^2192^^^^2193^^^^2206^^^^2207^^^^220a%
  ^^^^2218^^^^2228^^^^2229^^^^222a^^^^2235^^^^223c^^^^2260^^^^2261%
  ^^^^2262^^^^2264^^^^2265^^^^2282^^^^2283^^^^2296^^^^22a2^^^^22a3%
  ^^^^22a4^^^^22a5^^^^22c4^^^^2308^^^^230a^^^^2336^^^^2337^^^^2339%
  ^^^^233b^^^^233d^^^^233f^^^^2340^^^^2342^^^^2347^^^^2348^^^^2349%
  ^^^^234b^^^^234e^^^^2350^^^^2352^^^^2355^^^^2357^^^^2359^^^^235d%
  ^^^^235e^^^^235f^^^^2361^^^^2362^^^^2363^^^^2364^^^^2365^^^^2368%
  ^^^^236a^^^^236b^^^^236c^^^^2371^^^^2372^^^^2373^^^^2374^^^^2375%
  ^^^^2377^^^^2378^^^^237a^^^^2395^^^^25af^^^^25ca^^^^25cb%
  ^^00}
\lst@RestoreCatcodes
\makeatother

\bibliographystyle{plainyr}

\title{Linguistic Relativity and Programming Languages}

\author{
    Jiahao Chen
    \thanks{Computer Science and Artificial Intelligence Laboratory,
               Massachusetts Institute of Technology,
               Cambridge, Massachusetts, 02139 ({\tt jiahao@mit.edu})}
    %
    %\and
    %Alan Edelman
    %\thanks{Department of Mathematics and Computer Science and Artificial Intelligence Laboratory,
    %        Massachusetts Institute of Technology,
    %        Cambridge, Massachusetts, 02139 ({\tt edelman@mit.edu})}
}


\begin{document}

\maketitle

\begin{abstract}
My abstract.
\end{abstract}

\begin{keywords}
    programming languages
\end{keywords}

\section{Each decade has its own programming languages}

Each discipline has its own favorite languages: applied mathematics has MATLAB,
web applications have JavaScript, and high-performance computing still uses
Fortran, accompanied by Python~\cite{scipy} and even Tcl~\cite{Phillips2014}.
Statistical computing, of course, is associated strongly with R. Yet the
boundaries of these seemingly absolute fiefdoms in the kingdom of computing
turn out to be surprisingly malleable on the time scale of decades. Statistical
computing came to prominence with PL/I in the 70s, APL in the 80s, and
XLISP-STAT in the 90s before the relatively modern advent of S and
iR~\cite{deLeeuw2005}. In truth, programming languages come and go beyond the
time scale of single years or even PhD studentships.

So what makes a programming language suitable for the demands of a scientific
discipline like statistical computing?  Discussing pros and cons of different
languages can get bogged down in absolutist statements about what ``can'' and
``cannot'' be done in a language. On some level such statements are absurd,
given that all sufficiently complicated programming languages are Turing
complete, and therefore have the same computational power in the sense of
Turing equivalence. Thus anything that can be done in one Turing-complete
language \textit{must} be doable in another Turing-complete language. Instead,
the answer to the question of suitability must necessarily be ensconced in
``softer'' concepts about ease of use and expressiveness, concepts that are
hard to define precisely but are nonetheless responsible for shaping the
adoption of programming languages.

This paper explores how the suitability of programming languages is related to
expressiveness: what abstractions exist in a given programming language that
map onto ideas that a programmer would want to implement? Closely related is
the notion of idiomaticness: would an experienced programmer in a particular
language recognize and accept a given piece of code as ``idiomatic''?



\subsection{Linguistic relativity and programming languages}

To discuss the suitability of programming languages, I will borrow notions from
the study of \textit{human} languages, linguistics. In particular, I will adopt
the controversial concept of linguistic relativity~\cite{Gumperz1996}, or the
Sapir--Whorf hypothesis~\cite{Brown1976}, and argue that the idea that (human)
languages determine or even constrain cognition has its relevance to computer
languages and programming.

Some of the original writings of Sapir and Whorf seem particularly relevant to
the discussion. Here are some choice quotations:

\begin{quotation}
Human beings do not live in the objective world alone,[...] but are very much
at the mercy of the particular language which has become the medium of
expression for their society [...] [T]he `real world' is to a large extent
unconsciously built up on the language habits of the group.~\cite{Sapir1929}
\end{quotation}

Sapir wrote about human languages, in particular contrasting native American
languages like Hopi against Occidental languages like English. Nevertheless,
programmers would immediately recognize these words about ``language habits''
as echoing a parallel worldview in computer languages, being themselves human
constructs designed to abstract away unwanted, low level machine details.
Some examples of these programming language habits may include:

``Always put data in a data frame''

``Never write for loops; vectorize your code to gain performance.''

Some ``language habits'' can be as banal as choosing between 0- or 1-based
indexing, leading to notoriously unproductive flame wars.  Others are more
subtle. For example, MATLAB treats vectors like column matrices, and therefore
allow operations on one-dimensional objects like \lstinline|v[(2,1)]| indexing
with two numbers, which are disallowed in many other languages like C. We can
trace the different indexing behaviors back to different mathematical starting
points---whereas most languages treat vectors as one-dimensional arrays, i.e.\
``flat'' sequences of numbers, MATLAB by virtue of treating most objects like
matrices, assumes that vectors by default are \textit{column} vectors, and
therefore behave just matrices with one column.

The fact that such discussions of language habits tend to be emotionally
charged is also not a coincidence. Whorf wrote:

\begin{quotation}
[E]very person [...] carries through life certain na\"ive but deeply rooted
idea about talking and its relation to thinking. Because of their firm
connection with speech habits that have become unconscious and automatic, these
notions tend to be intolerant of opposition.~\cite{Whorf1956sl}
\end{quotation}

Replace ``talking'' with ``writing code'', and the analogy between speech and
computer programs could hardly be plainer. An experienced programmer,
practically by definition, internalizes the boilerplate and design patterns in
code as ``unconscious and automatic'' idioms to be regurgitated on demand
(preferably with an editor or IDE that helps reinforce these idioms
automatically). To the fluent Java programmer, wrapping everything in a class
must be second nature, just as the R user is accustomed to seeing data in a
data frame, or whitespace sensitivity to the Pythonista.  Allowing for code as
a generalization of speech, one could argue that Whorf's observation predicted
the very phenomenon of flame wars over programming language design!

In the rest of this paper, I will make use of another insight from Whorf:

\begin{quotation}
Through [linguistic knowledge], the world as seen from the diverse viewpoints of
other social groups, that we have thought of as alien, becomes intelligible in
new terms. Alienness turns into a new and often clarifyign way of looking at
things.~\cite{Whorf1956lmr}
\end{quotation}

I will present a simple, stereotypical data science task and show how solutions
may be implemented in different computer languages, not all of which may
necessarily be familiar to the reader or the typical user of statistical
computing. This side-by-side comparison of the familiar and unfamiliar will
hopefully aid to highlight similarities and differences between the
abstractions expressed within the codes.



\section{A simple data science task: split, apply, combine}

Here is a simple data analysis task that is perhaps emblematic of our house
sharing, carpooling times. Suppose I am a data scientist working at a ride
sharing company and here are the user ratings data for the last ten trips taken
by a particular driver:

\begin{tabular}{r|rrrrrrrrrr}
userid &
381    & 1291   & 3992   & 193942 & 9493   &
381    & 3992   & 381    & 3992   & 193942 \tabularnewline
rating &
5 & 4 & 4 & 4 & 5 & 5 & 5 & 3 & 5 & 4
\end{tabular}

Suppose also that I am interested in working out the average rating given by
each unique user. A seasoned R user might immediately recognize this task
as a ``split-apply-combine'' problem, which could be solved using the
\lstinline|dplyr| package as follows~\cite{Wickham2011}:

\begin{lstlisting}{R}
library(dplyr);
userid = c(381, 1291, 3992, 193942, 9493, 381,
  3992, 381, 3992, 193942)
rating = c(5, 4, 4, 4, 5, 5, 5, 3, 5, 4)
mycar = data.frame(rating, userid)
summarize(group_by(mycar, userid), avgrating=mean(rating))
\end{lstlisting}
\begin{verbatim}
# A tibble: 5 x 2
  userid avgrating
   <dbl>     <dbl>
1    381  4.333333
2   1291  4.000000
3   3992  4.666667
4   9493  5.000000
5 193942  4.000000
\end{verbatim}

The key computation is expressed by the \lstinline|summarize| function, a
higher-order function which combines the data in the \lstinline|mycar| data
frame after being split by (grouped by) \lstinline|userid| and had the function
\lstinline|mean| applied to each group.  This function is provided by
\lstinline|dplyr| and is perfectly well-suited to the split-apply-combine task.
Now let's look at how the same idiom can be expressed in other programming
languages.



\section{MATLAB: split-apply-combine on matrices}

MATLAB is more often thought of as a language for scientific computing rather
than statistical computing. Nevertheless, MATLAB provides a higher order
function, \lstinline|accumarray|, which is perfectly suited to
split-apply-combine computations. Even MATLAB seems to admit that
\lstinline|accumarray| is ``under-appreciated''~\cite{underappreciated};
nevertheless, the function does the job admirably:

\begin{lstlisting}{Matlab}
userids = [381; 1291; 3992; 193942; 9493; 381; 3992; 381; 3992;
  193942];
ratings = [5; 4; 4; 4; 5; 5; 5; 3; 5; 4];
accumarray(userids,ratings,[],@mean,[],true)
\end{lstlisting}
\begin{verbatim}
ans =

                (381,1)                      4.3333
               (1291,1)                      4.0000
               (3992,1)                      4.6667
               (9493,1)                      5.0000
             (193942,1)                      4.0000
\end{verbatim}

Unlike R, which was designed from the beginning around data frames as one of
the fundamental data structures, MATLAB was originally designed with matrices
as the sole data structure~\cite{Moler1980,Moler1982}. While MATLAB as of
R2013b now provides tables as a data structure~\cite{Shure2013}, most of the
base language is still built around matrices and does not work with tables.
\lstinline|accumarray| is one example of the base language that is designed
around matrices.

It can be difficult to determine from the documentation of
\lstinline|accumarray|~\cite{accumarray} that it is a function that solves the
split-apply-combine problem. The first complete sentence in the documentation
states that \lstinline|A=accumarray(val,subs)| ``returns array A by
accumulating elements of vector \lstinline|val| using the subscripts
\lstinline|subs|''. In other words, the most basic use of
\lstinline|accumarray| is to split data in  \lstinline|val| into subsets
grouped by the values of their corresponding entries in \lstinline|val|, with
the summation (accumulation) function applied to each subset. It is clear that
the function is generalizable: a different function can be specified in the
fourth positional argument (MATLAB does not support keyword arguments), but in
order to do so, a default argument must be specified for the third argument.
Finally, the last argument \lstinline|true| specifies that the output should be
returned as a sparse matrix, otherwise the result would be a $193942\times1$
dense matrix with most of the entries zero.



\section{APL: split-apply-combine using array operations}

APL is a language that is built around a single data structure, the
array.~\footnote{Some modern implementations such as Dyalog APL~\cite{dyalog15}
have nonstandard extensions that provide support for object-oriented
programming in the form of classes, but we won't consider them here.} APL does
not provide a standard idiom for solving the split-apply-combine problem;
instead, the APL programmer must express split-apply-combine on their own using
lower-level array computations.

One implementation of split-apply-combine might look like this:

\begin{lstlisting}[language=apl]
mean‚Üê{+/‚çµ√∑‚ç¥‚çµ}
uniqfy‚Üê{‚çµ[‚çã‚çµ]}‚à™
‚àáa‚Üêv splitby k
a‚Üê{(‚çµ‚ç∑k)/v}¬®uniqfy k
‚àá
summarizeby‚Üê{(uniqfy ‚çµ),[1.5]mean¬®(‚ç∫ splitby ‚çµ)}
u‚Üê381 1291 3992 193942 9493 381 3992 381 3992 193942
r‚Üê5 4 4 4 5 5 5 3 5 4
]display r summarizeby u
\end{lstlisting}
\begin{verbatim}
‚îå‚Üí‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚Üì   381 4.333333333‚îÇ
‚îÇ  1291 4          ‚îÇ
‚îÇ  3992 4.666666667‚îÇ
‚îÇ  9493 5          ‚îÇ
‚îÇ193942 4          ‚îÇ
‚îî~‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
\end{verbatim}

APL functions can take at most two arguments; further arguments must be
specified in ``concealed arguments'', which are variables in global scope.
This solution chose to hard code the function being applied (\lstinline|mean|)
into the higher-level \lstinline|summarizeby| function. Furthermore, dyadic APL
functions must be specified in place, which suggests the name
\lstinline|summarizeby| rather than \lstinline|summarize| as being more natural
to an English speaker. Notably, the expression \lstinline|r summarizeby u|
aligns with the SVO (subject-verb-object) order of English, which can explain
the intuition for why the name \lstinline|summarizeby| may be preferred.

The primary data structure used to implement the ``split'' stage is the nested
array, which allows for the representation of ragged matrices, or list of lists
with unequal lengths. The nested array has long been advocated as the primary
tool for statistical computation\cite{Anscombe1981,Friendly1994}. In this case,
the nested array is generated by the \lstinline|(‚çµ‚ç∑k)/v¬®| expression, which
extracts each subset of \lstinline|v| by common values \lstinline|k|. The
\lstinline|splitby| function produces the result

\begin{lstlisting}{apl}
]display r splitby u
\end{lstlisting}
\begin{verbatim}
‚îå‚Üí‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ‚îå‚Üí‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚Üí‚îê ‚îå‚Üí‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚Üí‚îê ‚îå‚Üí‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ5 5 3‚îÇ ‚îÇ4‚îÇ ‚îÇ4 5 5‚îÇ ‚îÇ5‚îÇ ‚îÇ4 4‚îÇ ‚îÇ
‚îÇ ‚îî~‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî~‚îò ‚îî~‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî~‚îò ‚îî~‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚àä‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
\end{verbatim}

corresponding to the keys

\begin{lstlisting}{apl}
]display uniqfy u
\end{lstlisting}
\begin{verbatim}
‚îå‚Üí‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ381 1291 3992 9493 193942‚îÇ
‚îî~‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
\end{verbatim}

The ``apply'' stage of the computation uses APL's built-in diaeresis
(\lstinline|¬®|, ``over each'') function. Finally, the ``combine'' stage
produces a two-column matrix, with the first column containing the unique keys
and the second column containing the required means. This matrix is produced by
the \lstinline|,[1.5]| expression, which ``laminates'' its two arguments
together.

Notably, the APL solution might be considered by some expert programmers to be
not idiomatic. Instead, there is a long tradition of writing concise one-line
APL solutions to various problems, and for this problem, such a solution might
look like

\begin{lstlisting}{language=apl}
{‚çµ,[1.5]{mean¬®{(‚çµ‚ç∑u)/r}¬®‚çµ}¬®‚çµ}{‚çµ[‚çã‚çµ]}‚à™u
\end{lstlisting}



\section{Julia}

The last language I will consider here is Julia, a general-purpose programming
language that was originally designed for technical
computing~\cite{Bezanson2015}.  Julia's thesis
is actually quite simple.  Why not design a language that is easy for both
compilers and programmers to understand?
Why is language important anyway?



\section{Conclusions}

\section*{Acknowledgments}

I would like to thank the Julia developer community for many useful
discussions, in particular Alan Edelman for the discussion of how
\lstinline|accumarray| may be implemented in Julia.

\bibliography{bib/bib}

\end{document}
